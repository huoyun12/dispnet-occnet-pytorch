# DispNet-OccNet 论文复现计划

## 项目概述

复现论文 "Unsupervised Light Field Depth Estimation via Multi-view Feature Matching with Occlusion Prediction" (IEEE TIP)

## 核心网络架构

### 1. DispNet（视差估计网络）

* **特征提取器**: Residual blocks + ASPP (空洞空间金字塔池化)

* **代价体构建**: 基于方差的特征匹配

* **Coarse-to-fine 结构**: 粗视差分支 + 残差 refinement 分支

* **视差回归**: soft argmin

### 2. OccNet（遮挡预测网络）

* **结构**: U-Net with residual blocks and skip connections

* **输入**: warped views + disparity map

* **输出**: confidence maps (用于加权 photometric loss)

## 损失函数

```
ℓ_full = ℓ_wpm + ℓ_rec + α₁ℓ_SSIM + α₂ℓ_smd + α₃ℓ_smo
```

* ℓ\_wpm: 加权 photometric loss

* ℓ\_rec: 重建损失

* ℓ\_SSIM: 结构相似性损失 (α₁=1)

* ℓ\_smd: 视差平滑损失 (α₂=0.1)

* ℓ\_smo: 遮挡平滑损失 (α₃=0.05)

## 实现步骤

### 第一阶段：项目基础结构 (文件)

1. 创建 configs/ 目录和配置文件
2. 创建 models/ 目录实现网络
3. 创建 utils/ 目录实现工具函数
4. 创建 data/ 目录实现数据加载，这个我目录我已经创建，你只需要阅读其中的数据集并懂得如何加载即可
5. 创建 scripts/ 目录实现训练脚本

### 第二阶段：网络实现

1. **特征提取器** (`models/dispnet.py`)

   * ResidualBlock 实现

   * ASPP 模块实现

   * FeatureExtractor 主类

2. **DispNet 主网络** (`models/dispnet.py`)

   * 方差基特征匹配构建 cost volume

   * Cost filters (3D residual blocks)

   * Disparity regression (soft argmin)

   * Coarse-to-fine refinement

3. **OccNet** (`models/occnet.py`)

   * U-Net 编码器-解码器结构

   * Confidence map 输出

### 第三阶段：损失函数和训练

1. **损失函数** (`utils/losses.py`)

   * Weighted Photometric Loss

   * Reconstruction Loss

   * SSIM Loss

   * Smoothness Loss (edge-aware)

   * Occlusion Smoothness Loss

2. **训练脚本** (`train.py`)

   * 数据加载和增强

   * 联合训练 DispNet + OccNet

   * 多视图组合输入

   * Checkpoint 保存

### 第四阶段：推理和评估

1. **推理脚本** (`inference.py`)

   * 多视图组合推理

   * 视差缩放和旋转

   * 多视差融合策略

2. **评估脚本** (`evaluate.py`)

   * MSE 和 BPR 指标计算

   * 与论文结果对比

## 关键参数

* **DispNet**: 1.802M 参数

* **OccNet**: 0.113M 参数

* **Feature channels**: 最大 128

* **Cost filters**: 2 个

## 训练配置

* **密集光场**:

  * 视差范围: \[-12, 12], 间隔 1

  * 残差范围: \[-1, 1], 间隔 0.1

  * Batch size: 4

  * Learning rate: 1e-3, 每50 epoch × 0.8

  * Epochs: 500

* **稀疏光场**:

  * 视差范围: \[-20, 20], 间隔 1.2

  * 残差范围: \[-2, 2], 间隔 0.12

## 预期输出

* 完整的 PyTorch 实现

* 可训练模型

* 推理和评估脚本

* 与论文可对比的结果

